{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c10ff31",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772276c-cbbc-4947-944c-40adee456239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo\n",
    "#!pip install yfinance\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import yfinance as yf\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Ignore specific warnings (e.g., DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c01ca",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419b442-3ef8-494a-95e6-4d6c3ea7eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MongoDB client locally\n",
    "client = MongoClient()\n",
    "\n",
    "# Access the database and the collection\n",
    "db = client[\"Dstoolsproject\"]  \n",
    "collection = db[\"Saudistocktdawul\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b61ea-1d05-49bb-9814-7e16bd3e82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a dataframe\n",
    "# Fetch data from the collection\n",
    "data = list(collection.find())  # find all documents and Converts the cursor to a list\n",
    "\n",
    "# Convert to DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sorting gathering the records of same company then the next company so on , and each company sorting the date in asc order \n",
    "df=df.sort_values(by=['symbol', 'date'], ascending=[True, True])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column 'id'\n",
    "df = df.drop(columns=['_id'])    # Not important for our data\n",
    "# Edit sector name\n",
    "df.rename(columns={'sectoer': 'sector'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c293b-7be3-4ac1-985a-b5be1a153600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display initial info about the dataset\n",
    "print(\"Initial dataset information:\")   # There is nulls in open , high , low , no of trades\n",
    "print(df.info())\n",
    "print(\"\\n\\nSummary statistics:\")        # we got from this that we have zeros in close and the last three col \n",
    "print(df.describe())                    # The data starts from 31-12-2001 to 23-4-2020                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb690cb5",
   "metadata": {},
   "source": [
    "### Get numbers of companies and sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique companies\n",
    "print(df[['symbol', 'trading_name ', 'sector']].drop_duplicates())    # 200 company\n",
    "   \n",
    "# Unique sectors\n",
    "df[['sector']].drop_duplicates()          # 11 sector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68b034",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458114a",
   "metadata": {},
   "source": [
    "## Dulpication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e65012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of duplicate rows in the dataset\n",
    "print(\"Number of duplications: \",df.duplicated().sum())   # 240 duplication\n",
    "\n",
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Reset the index for cleaner indexing after removing duplicates\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Make sure that that each company is recorded only once per day even if not same records\n",
    "print(\"Companies has multiple records in same day: \",df.duplicated(subset=['symbol', 'date']).sum(),\"\\n\")   \n",
    "\n",
    "# Print the DataFrame to verify duplicates are removed\n",
    "print(df.info())  # The data becomes 600571 instead if 600811"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780e0f7",
   "metadata": {},
   "source": [
    "## Missing values and Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30b6fa-91dd-4167-9748-344d99b8ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that we have nulls in open , high , low and no of trades\n",
    "\n",
    "# We observed that there is companies has a large amount of data by zeros and nulls, we will remove these companies\n",
    "\n",
    "# Get the unique symbols (companies) from the 'symbol' column\n",
    "unique_symbols = df['symbol'].unique()\n",
    "\n",
    "# Iterate through each unique symbol\n",
    "for symbol in unique_symbols:\n",
    "    # Filter the DataFrame for each symbol\n",
    "    symbol_data = df[df['symbol'] == symbol]\n",
    "    \n",
    "    # Get the trading name\n",
    "    trading_name = symbol_data['trading_name '].iloc[0] \n",
    "    \n",
    "    # Count the number of rows\n",
    "    row_count = symbol_data.shape[0]\n",
    "    \n",
    "    # Count the number of null values across all columns for this symbol\n",
    "    null_count = symbol_data.isnull().sum().sum()\n",
    "    \n",
    "    # List of specific columns to check for zeros\n",
    "    columns_to_check = ['open', 'high', 'low', 'close', 'volume_traded ', 'value_traded', 'no_trades ']  \n",
    "\n",
    "    # Filter rows in symbol_data where any of the specified columns have a zero\n",
    "    rows_with_zeros = symbol_data[symbol_data[columns_to_check].eq(0).any(axis=1)]\n",
    "    \n",
    "    # Print the companies has more than 500 missing values\n",
    "    if(null_count>500):\n",
    "        print(f\"Symbol: {symbol} - Trading name: {trading_name} -Rows: {row_count}, Nulls: {null_count}\")\n",
    "                                    # 13 company has more than 500 missing values\n",
    "                                    # 1120 and 1150 missing all trading values , 7040 from 5/2011 to 3/2012 zeros and nulls\n",
    "\n",
    "    # Check if rows_with_zeros exceed 500\n",
    "    if rows_with_zeros.shape[0] > 19:\n",
    "        # Print the result for the company\n",
    "        print(f\"Symbol: {symbol} - Trading name: {trading_name} - Rows with Zeros: {rows_with_zeros.shape[0]}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the companies that has nulls > 500 or zeros > 19    ==>      (21 company)\n",
    "# List of symbols to remove\n",
    "symbols_to_remove = [1120, 1150, 1330, 2100 ,2110, 2170 , 3008, 4012, 4051, 4061, 4070, 4130, 4160, 4191, 6012, 7020, 7040, 7201, 8110, 8150, 8270]\n",
    "\n",
    "# Filter out rows with these symbols\n",
    "df = df[~df['symbol'].isin(symbols_to_remove)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.info(),\"\\n\")   # Now we have nulls in open , high , low only\n",
    "\n",
    "\n",
    "# First fill na and zeros in open column by the close of previous day \n",
    "# The data already the date is arranged but avoid to fill open day in company by close of another company\n",
    "# fill the first day in company if has null or zero by close - change\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if df.loc[i, 'symbol'] == df.loc[i - 1, 'symbol']:  # Ensure it's the same symbol\n",
    "         if pd.isna(df.loc[i, 'open']) or df.loc[i, 'open'] == 0:  # Check for NaN or zero\n",
    "            df.loc[i, 'open'] = df.loc[i - 1, 'close']  # Fill with previous close\n",
    "    else:         \n",
    "         if pd.isna(df.loc[i, 'open']) or df.loc[i, 'open'] == 0:  # Check for NaN or zero\n",
    "            if df.loc[i,'close']!=0 :    # Ensure that the close not = 0\n",
    "                df.loc[i, 'open'] = df.loc[i,'close'] - df.loc[i,'change']  # Fill with close - change\n",
    "\n",
    "            \n",
    "print(df.info())   # Now we have nulls in high , low only\n",
    "\n",
    "# Drop all rows where 'open' is NaN\n",
    "df = df[df['open'].notna()]   # 3 rows\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d8dd7",
   "metadata": {},
   "source": [
    "### Get numbers of companies and sectors after drop some companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique companies\n",
    "print(df[['symbol', 'trading_name ', 'sector']].drop_duplicates())    # 179 company \n",
    "   \n",
    "# Unique sectors\n",
    "df[['sector']].drop_duplicates()                    # Still 11 sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows where 'close' column equals 0\n",
    "zero_close_count = (df['close'] == 0).sum()\n",
    "print(f\"Number of rows with 'close' == 0: {zero_close_count}\")   # 13 rows\n",
    "\n",
    "# Remove zeros and fill it by open of next day\n",
    "for i in range(len(df) - 1):  # Skip the last row, as there's no next row for it\n",
    "    if df.loc[i, 'close'] == 0 and df.loc[i, 'symbol'] == df.loc[i + 1, 'symbol'] :\n",
    "        # Replace the 'close' with the 'open' of the next row (same symbol group)\n",
    "        df.loc[i, 'close'] = df.loc[i + 1, 'open']\n",
    "        \n",
    "# Count rows where 'close' column equals 0\n",
    "zero_close_count = (df['close'] == 0).sum()\n",
    "print(f\"Number of rows with 'close' == 0: {zero_close_count}\\n\") \n",
    "\n",
    "# Drop rows where 'close' equals 0\n",
    "df = df[df['close'] != 0]  # 5 rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zeros in the specified columns\n",
    "columns_to_check = ['volume_traded ', 'value_traded', 'no_trades ']\n",
    "\n",
    "# Iterate over the columns and count zeros\n",
    "for col in columns_to_check:\n",
    "    zero_count = (df[col] == 0).sum()  # Count rows where the column is 0\n",
    "    print(f\"Column '{col}' has {zero_count} zeros.\")\n",
    "\n",
    "\n",
    "# List of columns to check and replace zeros\n",
    "columns_to_check = ['volume_traded ', 'value_traded', 'no_trades ']\n",
    "\n",
    "# Iterate over the columns\n",
    "for col in columns_to_check:\n",
    "    # Replace zeros with the mean of the column within the same symbol group\n",
    "    df[col] = df.groupby('symbol')[col].transform(lambda x: x.replace(0, x.mean()) if not x.empty else x)\n",
    "\n",
    "# Replace NaN or zero values in 'high' with the max of 'open' and 'close'\n",
    "df['high'] = df.apply(lambda row: max(row['open'], row['close']) if pd.isna(row['high']) or row['high'] == 0 else row['high'], axis=1)\n",
    "\n",
    "# Replace NaN or zero values in 'low' with the min of 'open' and 'close'\n",
    "df['low'] = df.apply(lambda row: min(row['open'], row['close']) if pd.isna(row['low']) or row['low'] == 0 else row['low'], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df.info())  # No nulls no zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3b9fd",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d3b5b",
   "metadata": {},
   "source": [
    "### Boxplots before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric columns for which we want to create box plots\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume_traded ', 'value_traded', 'no_trades ']\n",
    "\n",
    "# Group the data by 'symbol'\n",
    "grouped = df.groupby('symbol')\n",
    "\n",
    "# Create a box plot for each company for each column\n",
    "for symbol, group in grouped:\n",
    "    print(f\"Box plots for Company Symbol: {symbol}\")\n",
    "    \n",
    "    # Create a figure for the company\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Iterate over numeric columns and create subplots\n",
    "    for i, col in enumerate(numeric_cols, 1):\n",
    "        plt.subplot(2, 4, i)  # Adjust subplot layout (2 rows, 4 columns)\n",
    "        sns.boxplot(data=group, y=col, palette=\"Set3\")\n",
    "        plt.title(f\"{col} (Symbol: {symbol})\")\n",
    "        plt.ylabel(col)\n",
    "        plt.xticks([])  # Remove x-axis ticks\n",
    "    \n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df5a28",
   "metadata": {},
   "source": [
    "### Removing outliers and save in new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers based on IQR\n",
    "def remove_outliers(group, cols):\n",
    "    for col in cols:\n",
    "        Q1 = group[col].quantile(0.25)  # 25th percentile\n",
    "        Q3 = group[col].quantile(0.75)  # 75th percentile\n",
    "        IQR = Q3 - Q1                   # Interquartile range\n",
    "        lower_bound = Q1 - 1.0 * IQR    # Lower bound\n",
    "        upper_bound = Q3 + 1.0 * IQR    # Upper bound\n",
    "        \n",
    "        # Remove rows where the column value is outside the bounds\n",
    "        group = group[(group[col] >= lower_bound) & (group[col] <= upper_bound)]\n",
    "    return group\n",
    "\n",
    "\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume_traded ', 'value_traded', 'no_trades ']\n",
    "# Apply the function to remove outliers for each company\n",
    "df_cleaned = df.groupby('symbol').apply(lambda g: remove_outliers(g, numeric_cols))  # New df => df_cleaned\n",
    "\n",
    "# Reset the index after removing outliers\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print information about the cleaned dataset\n",
    "print(f\"Original DataFrame rows: {df.shape[0]}\")\n",
    "print(f\"Cleaned DataFrame rows: {df_cleaned.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04655e36",
   "metadata": {},
   "source": [
    "### Boxplots after removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'symbol' (company)\n",
    "grouped = df_cleaned.groupby('symbol')\n",
    "\n",
    "# Iterate over each group (company)\n",
    "for symbol, group in grouped:\n",
    "    print(f\"Box plots for Company Symbol: {symbol}\")\n",
    "    \n",
    "    # Create a figure for the company\n",
    "    plt.figure(figsize=(12, 6))  # Adjust the size of the figure\n",
    "    \n",
    "    # Iterate over numeric columns and create subplots\n",
    "    for i, col in enumerate(numeric_cols, 1):\n",
    "        plt.subplot(2, 4, i)  # Adjust subplot layout (2 rows, 4 columns)\n",
    "        sns.boxplot(data=group, y=col, palette=\"Set3\")\n",
    "        plt.title(f\"{col} (Symbol: {symbol})\")\n",
    "        plt.ylabel(col)\n",
    "        plt.xticks([])  # Remove x-axis ticks for cleaner appearance\n",
    "    \n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()                             # still there is outliers but less than before \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bea63",
   "metadata": {},
   "source": [
    "### Adding New columns to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column 'avg_price' to the dataframe\n",
    "df_cleaned['avg_price'] = (df_cleaned['open'] + df_cleaned['high'] + df_cleaned['low'] + df_cleaned['close']) / 4\n",
    "\n",
    "\n",
    "# Add a column 'year' to the dataframe\n",
    "df_cleaned['year'] = df_cleaned['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328df0f9",
   "metadata": {},
   "source": [
    "# Visualizations and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c570b9",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns from the DataFrame\n",
    "numeric_df = df_cleaned.select_dtypes(include=['number'])\n",
    "numeric_df = numeric_df.drop(columns=['symbol'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "    \n",
    "# Create the mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "    \n",
    "# Create the heatmap\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    mask=mask,\n",
    "    cmap=sns.diverging_palette(180, 10, as_cmap=True),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    linewidths=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "    \n",
    "# Fix for matplotlib bug that cuts off the top/bottom\n",
    "b, t = plt.ylim()  # Discover the values for bottom and top\n",
    "b += 0.5  # Add 0.5 to the bottom\n",
    "t -= 0.5  # Subtract 0.5 from the top\n",
    "plt.ylim(b, t)  # Update the ylim(bottom, top) values\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83571db",
   "metadata": {},
   "source": [
    "### Distribution of sectors in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'sector' and count the occurrences\n",
    "sector_counts = df_cleaned['sector'].value_counts()\n",
    "\n",
    "# Use a more vibrant color palette (e.g., \"muted\" or \"deep\")\n",
    "colors = sns.color_palette(\"deep\", len(sector_counts))\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sector_counts, labels=sector_counts.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "# external legend due to the labels are too close\n",
    "plt.legend(sector_counts.index, title=\"Sector\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Set title and display the plot\n",
    "plt.title('Distribution of Sector')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c3d4c",
   "metadata": {},
   "source": [
    "### Number of companies in each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_company_counts = df_cleaned.groupby('sector')['name'].nunique().reset_index()\n",
    "sector_company_counts_sorted = sector_company_counts.sort_values(by='name', ascending=False)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='name', y='sector', data=sector_company_counts_sorted, palette='viridis')\n",
    "plt.title('Number of Companies per Sector', fontsize=16)\n",
    "plt.xlabel('Number of Companies', fontsize=12)\n",
    "plt.ylabel('Sector', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0915161",
   "metadata": {},
   "source": [
    "### Mean of numerical data from Saudi Tadawul stock market over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by year and calculate the mean for the relevant columns\n",
    "yearly_data = df_cleaned.groupby('year')[['open', 'high', 'low', 'close', 'volume_traded ', 'no_trades ', 'value_traded']].mean()\n",
    "\n",
    "# Plot the changes over the years for each of the relevant columns\n",
    "plt.figure(figsize=(12, 30))  # Adjusted height to fit all 7 plots\n",
    "\n",
    "# List of columns to plot\n",
    "columns_to_plot = ['open', 'high', 'low', 'close', 'volume_traded ', 'no_trades ', 'value_traded']\n",
    "\n",
    "# Create subplots for each column (arranging them in a column)\n",
    "for i, column in enumerate(columns_to_plot, 1):\n",
    "    plt.subplot(7, 1, i)  # 7 rows, 1 column\n",
    "    plt.plot(yearly_data.index, yearly_data[column], marker='o', linestyle='-', label=column)\n",
    "    plt.title(f'{column} Over Years')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(f'{column.capitalize()}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8ccc4",
   "metadata": {},
   "source": [
    "### Total trading volume and total trading value for each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and set up the subplots (2 plots side by side)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))  # 1 row, 2 columns with larger size\n",
    "\n",
    "# First plot: Total Trading Volume Across Sectors\n",
    "sector_volume_sum = df_cleaned.groupby('sector')['volume_traded '].sum().reset_index()\n",
    "\n",
    "# Create a bar plot for the summed volume_traded per sector\n",
    "sns.barplot(x='sector', y='volume_traded ', data=sector_volume_sum, palette=\"Set2\", ax=axes[0])\n",
    "\n",
    "# Customize the first plot\n",
    "axes[0].set_title('Total Trading Volume Across Sectors')\n",
    "axes[0].set_xlabel('Sector')\n",
    "axes[0].set_ylabel('Total Volume Traded')\n",
    "axes[0].tick_params(axis='x', rotation=90)  # Rotate sector labels for better visibility\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Second plot: Total Trading Value Across Sectors\n",
    "sector_value_sum = df_cleaned.groupby('sector')['value_traded'].sum().reset_index()\n",
    "\n",
    "# Create a bar plot for the summed value_traded per sector\n",
    "sns.barplot(x='sector', y='value_traded', data=sector_value_sum, palette=\"Set2\", ax=axes[1])\n",
    "\n",
    "# Customize the second plot\n",
    "axes[1].set_title('Total Trading Value Across Sectors')\n",
    "axes[1].set_xlabel('Sector')\n",
    "axes[1].set_ylabel('Total Value Traded')\n",
    "axes[1].tick_params(axis='x', rotation=90)  # Rotate sector labels for better visibility\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000640d",
   "metadata": {},
   "source": [
    "### Average price for each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average closing price per sector\n",
    "sector_avg = df_cleaned.groupby('sector')['avg_price'].mean().reset_index()\n",
    "\n",
    "# Sort by the average close price\n",
    "sector_avg_sorted = sector_avg.sort_values(by='avg_price', ascending=False)\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(sector_avg_sorted['sector'], sector_avg_sorted['avg_price'], color='coral')\n",
    "plt.xlabel('Average Price', fontsize=12)\n",
    "plt.ylabel('Sector', fontsize=12)\n",
    "plt.title('Average Price by Sector', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e18a47",
   "metadata": {},
   "source": [
    "### Top 10 companies in Saudi Tadawul stock market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c530662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and set up the subplots (2 plots side by side)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 15))  # 1 row, 2 columns\n",
    "\n",
    "# First plot: Top 10 Companies by Trading Volume (volume_traded)\n",
    "top_companies = df_cleaned.groupby('name')['volume_traded '].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Get the sectors for the top companies\n",
    "top_companies_sectors = df_cleaned[df_cleaned['name'].isin(top_companies.index)][['name', 'sector']].drop_duplicates()\n",
    "\n",
    "# Merge top companies with their sectors\n",
    "top_companies_with_sector = top_companies.index.to_frame()\n",
    "top_companies_with_sector['sector'] = top_companies_sectors.set_index('name').loc[top_companies.index, 'sector'].values\n",
    "\n",
    "# Create labels combining company names and sectors\n",
    "labels = [f\"{name} ({sector})\" for name, sector in zip(top_companies_with_sector['name'], top_companies_with_sector['sector'])]\n",
    "\n",
    "# Plot the first bar chart on the first subplot\n",
    "top_companies.plot(kind='bar', color='skyblue', ax=axes[0])\n",
    "axes[0].set_title('Top 10 Companies by Trading Volume')\n",
    "axes[0].set_xlabel('Company (Sector)')\n",
    "axes[0].set_ylabel('Total Trading Volume')\n",
    "axes[0].set_xticks(range(len(top_companies)))\n",
    "axes[0].set_xticklabels(labels, rotation=90)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Second plot: Top 10 Companies by Value Traded (value_traded)\n",
    "top_companies = df_cleaned.groupby('name')['value_traded'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Get the sectors for the top companies\n",
    "top_companies_sectors = df_cleaned[df_cleaned['name'].isin(top_companies.index)][['name', 'sector']].drop_duplicates()\n",
    "\n",
    "# Merge top companies with their sectors\n",
    "top_companies_with_sector = top_companies.index.to_frame()\n",
    "top_companies_with_sector['sector'] = top_companies_sectors.set_index('name').loc[top_companies.index, 'sector'].values\n",
    "\n",
    "# Create labels combining company names and sectors\n",
    "labels = [f\"{name} ({sector})\" for name, sector in zip(top_companies_with_sector['name'], top_companies_with_sector['sector'])]\n",
    "\n",
    "# Plot the second bar chart on the second subplot\n",
    "top_companies.plot(kind='bar', color='orange', ax=axes[1])\n",
    "axes[1].set_title('Top 10 Companies by Value Traded')\n",
    "axes[1].set_xlabel('Company (Sector)')\n",
    "axes[1].set_ylabel('Total Value Traded')\n",
    "axes[1].set_xticks(range(len(top_companies)))\n",
    "axes[1].set_xticklabels(labels, rotation=90)\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a3aaf",
   "metadata": {},
   "source": [
    "### Top 10 companies in Materials sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eade195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the Materials sector\n",
    "materials_sector = df_cleaned[df_cleaned['sector'] == 'Materials']\n",
    "\n",
    "# Group by 'symbol' or 'trading_name', and calculate the sum of 'volume_traded' and 'value_traded'\n",
    "top_companies = (\n",
    "    materials_sector.groupby(['symbol', 'name'])[['volume_traded ', 'value_traded']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort by 'volume_traded' and get the top 10\n",
    "top_volume = top_companies.nlargest(10, 'volume_traded ')\n",
    "\n",
    "# Sort by 'value_traded' and get the top 10\n",
    "top_value = top_companies.nlargest(10, 'value_traded')\n",
    "\n",
    "# Plot the bar charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Bar plot for top 10 by volume traded\n",
    "axes[0].bar(top_volume['name'], top_volume['volume_traded '], color='skyblue')\n",
    "axes[0].set_title('Top 10 Companies by Volume Traded (Materials Sector)')\n",
    "axes[0].set_ylabel('Volume Traded')\n",
    "axes[0].tick_params(axis='x', rotation=90, labelsize=10)\n",
    "\n",
    "# Bar plot for top 10 by value traded\n",
    "axes[1].bar(top_value['name'], top_value['value_traded'], color='orange')\n",
    "axes[1].set_title('Top 10 Companies by Value Traded (Materials Sector)')\n",
    "axes[1].set_ylabel('Value Traded')\n",
    "axes[1].tick_params(axis='x', rotation=90, labelsize=10)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be701a5",
   "metadata": {},
   "source": [
    "### Average price of each company in Materials sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price for each company in the Materials sector\n",
    "avg_price_companies = (\n",
    "    materials_sector.groupby(['symbol', 'name'])['avg_price']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by='avg_price', ascending=False)\n",
    ")\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.bar(avg_price_companies['name'], avg_price_companies['avg_price'], color='lightgreen')\n",
    "plt.title('Average Price of Companies in Materials Sector', fontsize=16)\n",
    "plt.xlabel('Company Name', fontsize=12)\n",
    "plt.ylabel('Average Price', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fbfbc",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ac9cc",
   "metadata": {},
   "source": [
    "### Choosing a specific company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a specific company to perform the model on it\n",
    "# will choose the company that has high no. of rows\n",
    "\n",
    "# Get the unique symbols (companies) from the 'symbol' column\n",
    "unique_symbols = df_cleaned['symbol'].unique()\n",
    "\n",
    "# Iterate through each unique symbol\n",
    "for symbol in unique_symbols:\n",
    "    # Filter the DataFrame for each symbol\n",
    "    symbol_data = df_cleaned[df_cleaned['symbol'] == symbol]\n",
    "    \n",
    "    # Get the trading name\n",
    "    trading_name = symbol_data['trading_name '].iloc[0] \n",
    "    \n",
    "    # Count the number of rows\n",
    "    row_count = symbol_data.shape[0]\n",
    "    \n",
    "    \n",
    "    # Print the companies has more than 3400 row\n",
    "    if(row_count>3400):\n",
    "        print(f\"Symbol: {symbol} - Trading name: {trading_name} -Rows: {row_count}\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ee6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for company with symbol 3020 (Has the highest amount of data)\n",
    "company_3020 = df_cleaned[df_cleaned['symbol'] == 3020]\n",
    "company_3020 = company_3020.reset_index(drop=True)\n",
    "company_3020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbaf70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first day in data and last day\n",
    "print(\"First day: \",company_3020['date'].min())\n",
    "print(\"Last day: \",company_3020['date'].max(),'\\n')\n",
    "\n",
    "\n",
    "# Display the updated dataframe with the new column\n",
    "company_3020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2186da",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadeee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only these columns\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume_traded ', 'value_traded', 'no_trades ','avg_price']\n",
    "company_3020_numeric = company_3020[numeric_cols]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = company_3020_numeric.corr()\n",
    "\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a33d1b",
   "metadata": {},
   "source": [
    "### Predict close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (X) and dependent variable (y)\n",
    "X = company_3020[['open','volume_traded ']]          # Features \n",
    "y = company_3020['close']                            # Target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "close_model = LinearRegression()\n",
    "close_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = close_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Coefficients:\", close_model.coef_)\n",
    "print(\"Model Intercept:\", close_model.intercept_)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize actual vs predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.xlabel(\"Actual Close Price\")\n",
    "plt.ylabel(\"Predicted Close Price\")\n",
    "plt.title(\"Actual vs Predicted Close Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d23f1",
   "metadata": {},
   "source": [
    "### Predict Value of trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aac357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (X) and dependent variable (y)\n",
    "X = company_3020[['open','volume_traded ','no_trades ']]    # Features\n",
    "y = company_3020['value_traded']                            # Target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the regression model\n",
    "value_model = LinearRegression()\n",
    "value_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = value_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Coefficients:\", value_model.coef_)\n",
    "print(\"Model Intercept:\", value_model.intercept_)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "\n",
    "                                        # We want to predict value of trades by open price , volume of trades, and\n",
    "                                        # no. of trades knowing that we dont know the avg price(price is not stable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee90b5",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock symbol and date range\n",
    "symbol = \"3020.SR\"  # stock symbol\n",
    "start_date = \"2020-04-21\"\n",
    "end_date = \"2024-12-19\"\n",
    "\n",
    "# Fetch the data\n",
    "stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Convert to DataFrame\n",
    "realdf = pd.DataFrame(stock_data)\n",
    "\n",
    "# Display the data\n",
    "realdf                      # without no of trades and value traded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbc640",
   "metadata": {},
   "source": [
    "## Preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Ticker' row/column and ensure clean column headers\n",
    "realdf.columns = realdf.columns.droplevel(0)  # Drop the 'Ticker' \n",
    "realdf.reset_index(inplace=True)  # Reset index to make 'Date' a regular column\n",
    "\n",
    "# Rename the columns to match the desired names\n",
    "realdf.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "\n",
    "# Ensure 'Date' is treated as a datetime column\n",
    "realdf['Date'] = pd.to_datetime(realdf['Date'])\n",
    "\n",
    "# Rearrange columns: swap 'Open' with 'Close' \n",
    "realdf = realdf[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "# sort by date\n",
    "realdf=realdf.sort_values(by=['Date'], ascending=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "realdf                       # 1159 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95084db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(realdf.isna().sum(),'\\n')   # 0 Nulls\n",
    "\n",
    "print(realdf.duplicated().sum(),'\\n')    # 0 duplications  \n",
    "\n",
    "print(realdf.info())\n",
    "\n",
    "# Define a function to remove outliers using the IQR method\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)  # First quartile (25%)\n",
    "        Q3 = df[col].quantile(0.75)  # Third quartile (75%)\n",
    "        IQR = Q3 - Q1  # Interquartile range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Filter out rows with outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Columns to check for outliers\n",
    "numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Remove outliers and save in a new DataFrame\n",
    "realdf_cleaned = remove_outliers(realdf.copy(), numeric_cols)\n",
    "realdf_cleaned.reset_index(inplace=True)\n",
    "\n",
    "# Output the cleaned DataFrame\n",
    "print(\"\\n\\nOutliers removed. Cleaned DataFrame saved in 'realdf_cleaned'.\")\n",
    "# Print information about the cleaned dataset\n",
    "print(f\"Original DataFrame rows: {realdf.shape[0]}\")\n",
    "print(f\"Cleaned DataFrame rows: {realdf_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18230ba",
   "metadata": {},
   "source": [
    "## Adding No_trades and value_traded from excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "file_path = r'C:\\Users\\tsarget\\OneDrive\\Desktop\\Rest of scraping data.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "complete_realdf = pd.read_excel(file_path)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "complete_realdf                     # 215 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6186cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Date' is treated as a datetime column\n",
    "complete_realdf['date'] = pd.to_datetime(complete_realdf['date'])\n",
    "\n",
    "# sort by date\n",
    "complete_realdf=complete_realdf.sort_values(by=['date'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960268c",
   "metadata": {},
   "source": [
    "### Merge the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68dbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Date' as index for both DataFrames\n",
    "complete_realdf.set_index('date', inplace=True)\n",
    "realdf_cleaned.set_index('Date', inplace=True)\n",
    "# Drop the 'Index' column after resetting the index\n",
    "realdf_cleaned.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Add the columns from realdf to complete_realdf\n",
    "complete_realdf[['open', 'high', 'low', 'close', 'volume']] = realdf_cleaned[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "# Arrange columns\n",
    "complete_realdf= complete_realdf[['open', 'high', 'low', 'close', 'volume','value_traded','no_trades']] \n",
    "\n",
    "# Rename columns in dataframes to be as the main dataframe\n",
    "complete_realdf.rename(columns={'volume': 'volume_traded ','no_trades': 'no_trades '}, inplace=True)\n",
    "realdf_cleaned.rename(columns={'Volume': 'volume_traded ', 'Open': 'open'}, inplace=True)\n",
    "\n",
    "# Reset the index if you need 'Date' back as a column\n",
    "complete_realdf.reset_index(inplace=True)\n",
    "\n",
    "complete_realdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34895c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_realdf.info())          # There is nulls\n",
    "\n",
    "# Drop all rows that contain any NaN values\n",
    "complete_realdf.dropna(inplace=True)\n",
    "complete_realdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae817db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers using the IQR method\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)  # First quartile (25%)\n",
    "        Q3 = df[col].quantile(0.75)  # Third quartile (75%)\n",
    "        IQR = Q3 - Q1  # Interquartile range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Filter out rows with outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Columns to check for outliers\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume_traded ' ,'value_traded', 'no_trades ']\n",
    "\n",
    "# Remove outliers and save in a new DataFrame\n",
    "complete_realdf = remove_outliers(complete_realdf.copy(), numeric_cols)\n",
    "complete_realdf.reset_index(inplace=True)\n",
    "\n",
    "# Output the cleaned DataFrame\n",
    "# Print information about the cleaned dataset\n",
    "print(f\"Cleaned complete DataFrame rows: {complete_realdf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce45235",
   "metadata": {},
   "source": [
    "# Testing the ML models on the scraping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from realdf\n",
    "X_new = realdf_cleaned[['open', 'volume_traded ']]  \n",
    "# Predict using the trained model\n",
    "y_new_pred = close_model.predict(X_new)\n",
    "\n",
    "# Add the predictions to the DataFrame for comparison or further analysis\n",
    "realdf_cleaned['predicted_close'] = y_new_pred\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(realdf_cleaned['Close'], y_new_pred)\n",
    "r2 = r2_score(realdf_cleaned['Close'], y_new_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "# Optional: Visualize the predicted vs. actual close prices (if actual close prices are available in realdf)\n",
    "if 'Close' in realdf.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(realdf_cleaned['Close'], realdf_cleaned['predicted_close'], alpha=0.6)\n",
    "    plt.xlabel(\"Actual Close Price\")\n",
    "    plt.ylabel(\"Predicted Close Price\")\n",
    "    plt.title(\"Actual vs Predicted Close Price\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Display a sample of the DataFrame with predictions\n",
    "realdf_cleaned[['Close', 'predicted_close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7726442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from realdf\n",
    "X_new = complete_realdf[['open', 'volume_traded ','no_trades ']]  \n",
    "# Predict using the trained model\n",
    "y_new_pred = value_model.predict(X_new)\n",
    "\n",
    "# Add the predictions to the DataFrame for comparison or further analysis\n",
    "complete_realdf['predicted_value'] = y_new_pred\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(complete_realdf['value_traded'], y_new_pred)\n",
    "r2 = r2_score(complete_realdf['value_traded'], y_new_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "\n",
    "# Optional: Visualize the predicted vs. actual close prices (if actual close prices are available in realdf)\n",
    "if 'value_traded' in complete_realdf.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(complete_realdf['value_traded'], complete_realdf['predicted_value'], alpha=0.6)\n",
    "    plt.xlabel(\"Actual value traded\")\n",
    "    plt.ylabel(\"Predicted value traded\")\n",
    "    plt.title(\"Actual vs Predicted value traded\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Display a sample of the DataFrame with predictions\n",
    "complete_realdf[['value_traded', 'predicted_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33960e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
